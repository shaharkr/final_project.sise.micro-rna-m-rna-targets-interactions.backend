#!/bin/bash
### sbatch config parameters must start with #SBATCH and must precede any other command. to ignore just add another # - like so ##SBATCH
#SBATCH --partition main                         ### specify partition name where to run a job. main - 7 days time limit
#SBATCH --time 7-00:00:00	                     ### limit the time of job running. Make sure it is not greater than the partition time limit!! Format: D-H:MM:SS
#SBATCH --job-name my_job2                   ### name of the job. replace my_job with your desired job name
#SBATCH --output my_job-id-%J.out                ### output log for running job - %J is the job number variable
#SBATCH --mail-user=efrco@post.bgu.ac.il      ### users email for sending job status notifications
#SBATCH --mail-type=BEGIN,END,FAIL             ### conditions when to send the email. ALL,BEGIN,END,FAIL, REQUEU, NONE
##SBATCH --cpus-per-task=6	# 6 cpus per task – use for multithreading, usually with --tasks=1
##SBATCH --tasks=4		# 4 processes – use for multiprocessing 

#SBATCH --mem=58G

### Print some data to output file ###
echo "SLURM_JOBID"=$SLURM_JOBID
echo "SLURM_JOB_NODELIST"=$SLURM_JOB_NODELIST


### activate a conda environment, replace my_env with your conda environment
### Start your code below ####
module load anaconda				### load anaconda module (must be present when working with conda environments)
source /home/efrco/.local/share/virtualenvs/efrco-master-BYjOffaj/bin/activate ### activate a conda environment, replace my_env with your conda 
python -u /sise/home/efrco/efrco-master/full_pipline.py



